{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"Dear Machine Learners,\n\n* This is my first time using *BERT* & *HuggingFace*, therefore I have decided to share this journey of discovery...\n* In this notebook, you will learn about the *BERT* model and its implementation with *TensorFlow, Keras* and *HuggingFace* to solve this competitions problematic.\n* I also haven't used *Kaggle* in a long time...\n* In this notebook, you will learn how to implement models for scoring, without the internet (a rule of this competition).\n* Thanks a lot to Jude Tchaye for his [NBME-TensorFlow-Bert-Baseline notebook](https://www.kaggle.com/code/tchaye59/nbme-tensorflow-bert-baseline) which I enriched with comments and ressources.\n* If you notice errors (english mistakes included) or have any questions do not hesitate to comment.\n\nHappy reading !","metadata":{}},{"cell_type":"markdown","source":"# Environment","metadata":{}},{"cell_type":"markdown","source":"In this part, we will understand the constraints of our working environment, and set a few things up.","metadata":{}},{"cell_type":"markdown","source":"## Importing libraries","metadata":{}},{"cell_type":"markdown","source":"Well, you probably already know about this...\n\n* *Imports the libraries for the project:*","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm.auto import tqdm\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import mixed_precision\nimport tensorflow_addons as tfa\nimport dill\nimport matplotlib.pyplot as plt\nimport transformers\nfrom transformers import AutoTokenizer, AutoConfig,TFAutoModel\nimport json\nimport matplotlib.pyplot as plt","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-28T00:45:21.147709Z","iopub.execute_input":"2022-04-28T00:45:21.148048Z","iopub.status.idle":"2022-04-28T00:45:28.956224Z","shell.execute_reply.started":"2022-04-28T00:45:21.147957Z","shell.execute_reply":"2022-04-28T00:45:28.955506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using *Kaggle notebooks* & Competition Rules","metadata":{}},{"cell_type":"markdown","source":"*To recap: in order to have access to the model while scoring we've added the outputs of this notebook to its inputs so that the output files persist when comitting*.\n\nIf like me, you haven't participated in a competition nor used the *Kaggle notebooks* in a while, this part should be of interest to you:\n* In order to submit *predictions* for scoring, we must provide a *Kaggle notebook* which outputs a \"predictions.csv\" file, with the required formating (*a prediction sample is provided, see the [competitions rules](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/overview/evaluation)*)...\n* When you submit, you actually launch a run of the *notebook*.\n* One important rule of the competition is: for *scoring*, the *notebook run* is happening *offline* (*the Internet setting must be off*, this is a rule of the competition)...\n* Which means that the *notebook run*, which is happening on the *Kaggle servers* won't be able to download models directly from the internet.\n* For this reason, we did add the *Output* of this *notebook* as an *Input* of this very same *notebook*. This means that the files outputed by the *notebook* during *Save & Run* will persist on the *Kaggle servers* as the *inputs* if the output files are *comitted*...\n* Note that after *commiting, refreshing* the *Input directory* is necessary (in the *notebooks file explorer*).\n* Which will enable us to load the model saved on the *Kaggle servers* even if the *Internet setting* is *off*.\n\nWhen you submit, the test.csv input samples will change so that the model infers on unseen data for scoring.","metadata":{}},{"cell_type":"markdown","source":"<img src= \"https://i.ibb.co/2Z4m2Gc/submit.png\" alt =\"Submit\" style='width: 400px;'>","metadata":{}},{"cell_type":"markdown","source":"## Notebook Parameters","metadata":{}},{"cell_type":"markdown","source":"We are initializing the following *parameters* to handle our *notebook configuration*:\n1. To ***add your own Dataset***: \n    1. add the **outputs of the cloned notebook to the inputs** ***(\"+ Add data\" button)***,\n    2. set **INPUT** to your *notebook name*.\n2. To ***train a new model*** for submission: \n    1. set the **MODEL_NAME** to the *HuggingFace model adress*, \n    2. set **TRAIN** to *True*, \n    3. set **RESET** to *True*,\n    4. **enable the internet**, \n    5. **save & run** the notebook on *GPU*, \n    6. **refresh the input dataset**.\n3. To ***submit for scoring***: \n    1. set **TRAIN** to *False*,\n    2. set **RESET** to *False*,\n    3. **disable the internet**,\n    4. **submit**.\n* *Optionnaly,* to ***reset the model & data files for retraining*** & re-downloading the model files from the web (from scracth, also useful if you did not add your input data):\n    1. set **TRAIN** to *True*,\n    2. set **RESET** to *True*, \n    3. **enable the internet**,\n    4. **run** & *experiment*.\n* *Optionnaly,* to *experiment with the committed pre-trained model & data*: \n    1. once **the model and data files are committed and refreshed**, \n    2. set **TRAIN** to *True*,\n    3. set **RESET** to *False*,\n    4. **run** & *experiment*.\n\n\n* *Sets the notebook parameters:*","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = 'roberta-base'\nTRAIN = True # True to train and evaluate the model\nRESET = True # True to retrain the same model without using committed model files, generates tokens data\nINPUT = 'nbme-tensorflow-bert-baseline' # The notebooks name","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:28.957888Z","iopub.execute_input":"2022-04-28T00:45:28.958127Z","iopub.status.idle":"2022-04-28T00:45:28.965745Z","shell.execute_reply.started":"2022-04-28T00:45:28.958096Z","shell.execute_reply":"2022-04-28T00:45:28.964791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Parameters","metadata":{}},{"cell_type":"markdown","source":"* *Sets the training parameters:*","metadata":{}},{"cell_type":"code","source":"TRAIN_SPLIT = 0.8\nBATCH_SIZE = 12\nEPOCHS = 20\nSEQUENCE_LENGTH = 512\nSEED = 999","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:59:55.384986Z","iopub.execute_input":"2022-04-28T00:59:55.385309Z","iopub.status.idle":"2022-04-28T00:59:55.389587Z","shell.execute_reply.started":"2022-04-28T00:59:55.385273Z","shell.execute_reply":"2022-04-28T00:59:55.388629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data State","metadata":{}},{"cell_type":"markdown","source":"* *Computes data state information:*","metadata":{}},{"cell_type":"code","source":"input_path = f'../input/{INPUT}/'\noutput_path = f'./'\n\nif RESET:\n    # If not resetting, use the model files already committed\n    data_exists = False\nelse:\n    # If reset, generates new data arrays for training\n    data_exists = os.path.exists(f'{input_path}/model.h5')\n\n# Prints status\nif data_exists:\n    print('''\n        Model & data found on the Kaggle servers. \n        Model & data will be read from the Kaggle disk. \n        Internet can be disabled and the comitted model can be submitted.\n    ''')    \nelse:\n    print('''\n        Model & data do not exist on the Kaggle servers.\n        Model will be downloaded from the cloud & data generated from scratch.\n        Save version with \"Save & Run All\" to save files on Kaggle.\n        If you saved & ran this notebook succesfully, refresh the Kaggle Input Data.\n        Set TRAIN, RESET to False & disable internet to Submit.\n    ''')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:28.982763Z","iopub.execute_input":"2022-04-28T00:45:28.983015Z","iopub.status.idle":"2022-04-28T00:45:28.991988Z","shell.execute_reply.started":"2022-04-28T00:45:28.982979Z","shell.execute_reply":"2022-04-28T00:45:28.991128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parallelization Configuration","metadata":{}},{"cell_type":"markdown","source":"This snippet manages settings for the compute configuration, I haven't dived too much into it but it kind of speaks for itself.\n\n* *Selects the appropriate settings for the configuration:*","metadata":{}},{"cell_type":"code","source":"# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU/GPU/multi-GPU/cluster-GPU detection code\n\ntry: # detect TPUs\n    tpu  = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\n    print('Using TPU')\n\nexcept ValueError: # detect GPUs\n    tpu = None\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-28T00:45:28.99335Z","iopub.execute_input":"2022-04-28T00:45:28.993679Z","iopub.status.idle":"2022-04-28T00:45:33.579433Z","shell.execute_reply.started":"2022-04-28T00:45:28.993643Z","shell.execute_reply":"2022-04-28T00:45:33.578527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Note that in order to render the parallelization effective, it is required to call the model building and fitting and predicting functions under a*** *with stragegy.scope():* ***call.***","metadata":{}},{"cell_type":"markdown","source":"## Notebook Configuration","metadata":{}},{"cell_type":"markdown","source":"\n\n* *There should be files in our input directory, including files of the model we trained last (save version using save and run all):*","metadata":{}},{"cell_type":"code","source":"os.listdir('../input/nbme-tensorflow-bert-baseline')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:33.581111Z","iopub.execute_input":"2022-04-28T00:45:33.58145Z","iopub.status.idle":"2022-04-28T00:45:33.59476Z","shell.execute_reply.started":"2022-04-28T00:45:33.581409Z","shell.execute_reply":"2022-04-28T00:45:33.594122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Sets a few things up:*","metadata":{}},{"cell_type":"code","source":"# Prevents Data Sharding\nos.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\noptions = tf.data.Options()\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n\n# Sets output size for plots\nplt.rcParams[\"figure.figsize\"] = (15, 10)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:33.597283Z","iopub.execute_input":"2022-04-28T00:45:33.597479Z","iopub.status.idle":"2022-04-28T00:45:33.603931Z","shell.execute_reply.started":"2022-04-28T00:45:33.597455Z","shell.execute_reply":"2022-04-28T00:45:33.603245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting Seeds","metadata":{}},{"cell_type":"markdown","source":"* *Sets the random seeds in order to obtain reproductible results:*","metadata":{}},{"cell_type":"code","source":"random.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:33.606388Z","iopub.execute_input":"2022-04-28T00:45:33.60664Z","iopub.status.idle":"2022-04-28T00:45:33.611784Z","shell.execute_reply.started":"2022-04-28T00:45:33.606604Z","shell.execute_reply":"2022-04-28T00:45:33.610844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Introduction","metadata":{}},{"cell_type":"markdown","source":"*In this part, I have summarized information about the BERT model, if you're not interested in theory, you should skip it.*","metadata":{}},{"cell_type":"markdown","source":"## Transformers","metadata":{}},{"cell_type":"markdown","source":"***This article makes for a good general introduction to the model: [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270).***\n\nThe *Google* BERT *(Bidirectional Encoder Representations from Transformers)* model which has been described in the [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf) article, was realease in 2018 and is one of the first transformer model *(following the release of the OpenAI GPT model)*.\n\n<img src= \"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono.svg\" alt =\"Timeline\" style='width: 800px;'>\n\n[*[Source]*](https://huggingface.co/course/chapter1/4?fw=pt)\n\nThe BERT model is a *auto-encoding Transformer* which allows the model to develop \"a statistical understanding of the language it has been trained on\" whithout requiring human labeling, a major advantage for Natural Langage Processing *(NLP)*, a field in which the labeled datasets are scarse *([How do Transformers work ?](https://huggingface.co/course/chapter1/4?fw=pt))*.\n\nThe BERT model has been pre-trained on large amounts of data *(Wikipedia)* on *Causal Language Modeling* & *Masked Language Modeling* tasks to aquire an understanding of the english language. More about the pre-training of the BERT model: [BERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding](https://arxiv.org/pdf/1810.04805.pdf).\n\nIt has achieved state-of-the-art performance in numerous NLP tasks, a major breakthrough for the machine learning community. More about the transformers architecture: [Transformer Neural Networks - EXPLAINED! (Attention is all you need)](https://www.youtube.com/watch?v=TQQlZhbC5ps). This article also develops the subject: [Transformers](https://towardsdatascience.com/transformers-89034557de14).\n\n*To simplify, the BERT model understands context by comparing the use of words in various documents.* For a deeper technical understanding of how the the model works, I recommend watching [BERT Neural Network - EXPLAINED!](https://www.youtube.com/watch?v=xI0HHN5XKDo).\n\n\nWe will fine-tune a variant of this model *(Facebook RoBERTa)* on our specific task to participate in the competition.","metadata":{}},{"cell_type":"markdown","source":"## RoBERTa","metadata":{}},{"cell_type":"markdown","source":"We have chosen the [*RoBERTa*](https://huggingface.co/docs/transformers/model_doc/roberta) model to experiment with, *(in its base configuration: [*RoBERTa base*](https://huggingface.co/roberta-base))*. \n\n\"RoBERTa iterates on BERT's pretraining procedure, including training the model longer, with bigger batches over more data; removing the next sentence prediction objective; training on longer sequences; and dynamically changing the masking pattern applied to the training data.\" *([*Pytorch Github*](https://github.com/pytorch/fairseq/blob/main/examples/roberta/README.md))*.\n\n***This article summarizes the key differences between BERT & RoBERTa and their effects: [Evolving with BERT: Introduction to RoBERTa](https://medium.com/analytics-vidhya/evolving-with-bert-introduction-to-roberta-5174ec0e7c82).***","metadata":{}},{"cell_type":"markdown","source":"## HuggingFace","metadata":{}},{"cell_type":"markdown","source":"[*HuggingFace*](https://huggingface.co/) provides, amongts over services, a very handy API *([the transformers library - Pypi](https://pypi.org/project/transformers/))* and a model repository to easily implement *pre-trained* transformers *(transfer learning)*, in combination with *TensorFlow* or *Pytorch*.\n\nIn this notebook, we will use the *transformers* library in combination with *TensorFlow* to download the model, tokenizer & configuration, and build a *top layer* to fine-tune the model to our specific task.\n","metadata":{}},{"cell_type":"markdown","source":"## Named-entity Recognition","metadata":{}},{"cell_type":"markdown","source":"Let's refer to the [competition description](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/overview): \"In this competition, you’ll identify specific clinical concepts in patient notes. Specifically, you'll develop an automated method to map clinical concepts from an exam rubric (e.g., “diminished appetite”) to various ways in which these concepts are expressed in clinical patient notes written by medical students (e.g., “eating less,” “clothes fit looser”)\".\n\nIn a nutshell, our objective is to fine-tune our model to recognize entities. According to *Papers with code*, Named-entity Recognition *(NER)* is \"the task of tagging entities in text with their corresponding type.\" *([Named Entity Recognition](https://paperswithcode.com/task/named-entity-recognition-ner/codeless))*.\n\n<img src= \"https://production-media.paperswithcode.com/thumbnails/task/task-0000000008-1eee4fae_Kb2RSZl.jpg\" alt =\"Example\" style='width: 300px;'>\n\n[*[Source]*](https://paperswithcode.com/task/named-entity-recognition-ner/codeless)\n\nTo do so, we will need to pass the appropriate embeddings to our model.","metadata":{}},{"cell_type":"markdown","source":"## Embeddings","metadata":{}},{"cell_type":"markdown","source":"In order to fine-tune the model, embeddings, which are numerical representations of the (textual) data *(as with any machine learning model)* are passed to the transformer model.\n\nThe embeddings are vectors that numericaly describe the characteristics of the data for the model to learn from. Here is an example for you to grasp what embeddings are:\n\n<img src= \"https://www.researchgate.net/profile/Akbar-Karimi-4/publication/338934952/figure/fig2/AS:853247933808640@1580441568270/BERT-word-embedding-layer-Devlin-et-al-2018.ppm\" alt =\"Embeddings\" style='width: 800px;'>\n\n[*[Source]*](https://www.researchgate.net/profile/Akbar-Karimi-4/publication/338934952/figure/fig2/AS:853247933808640@1580441568270/BERT-word-embedding-layer-Devlin-et-al-2018.ppm)\n\nFor our Named-entity Recognition task, we will use a variation of these embeddings:\n* Token embeddings that encodes the various words of our corpus documents thanks to a *Tokenizer*,\n* Positional embeddings which point to the indexes of the targets *(portions of the text that we aim to recognize the named-entities of)*,\n* Target embeddings with the actual labels of the target text portions to train our model (encoded with a *LabelEncoder*),\n* We won't use the Segments embeddings.\n\nIn order to implement the *Tokenization*, we will use the *transformers library from HuggingFace*.","metadata":{}},{"cell_type":"markdown","source":"## Processing","metadata":{}},{"cell_type":"markdown","source":"One of the main perks of BERT is that it requires fery few data preprocessing, thanks to the *Tokenizer class*: \"this tokenizer applies an end-to-end, text string to wordpiece tokenization. It first applies basic tokenization, followed by wordpiece tokenization.\" *([Tensorflow documentation](https://www.tensorflow.org/text/api_docs/python/text/BertTokenizer))*. *Note that in the case of RoBERTa, the tokenization model used is BPE.*\n\nAs we are using a pre-trained model from *HuggingFace*, the *Tokenizer* is included with its presets. The *Tokenizer* also allows for the inverse transformation of the *models logits* thanks to its *Decoder* component.\n\n***If you are interested in understanding how the Tokenizer itself works, this HuggingFace article explains it all: [The tokenization pipeline](https://huggingface.co/docs/tokenizers/python/latest/pipeline.html#example).***\n\nTo wrap it up, the transformers pipeline is pretty simple:\n\n<img src= \"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/4RDiRXhpZgAATU0AKgAAAAgABAE7AAIAAAAIAAAISodpAAQAAAABAAAIUpydAAEAAAAQAAAQyuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFRPU0hJQkEAAAWQAwACAAAAFAAAEKCQBAACAAAAFAAAELSSkQACAAAAAzkzAACSkgACAAAAAzkzAADqHAAHAAAIDAAACJQAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIyOjAzOjEzIDIwOjQyOjMwADIwMjI6MDM6MTMgMjA6NDI6MzAAAABUAE8AUwBIAEkAQgBBAAAA/+ELGmh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjItMDMtMTNUMjA6NDI6MzAuOTMxPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPlRPU0hJQkE8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgA/AOqAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACio7i4itbd57hxHEgyzN2rlrvxPeXD4sI1toecPIu6RvfHRfxz+FNJs3o4epW+E62iuDOo6qTk6rc/gsY/wDZaT+0NU/6C11+Uf8A8TV8jOv+zp/zL8f8jvaK4L+0NU/6C11+Uf8A8TR/aGqf9Ba6/KP/AOJo9mx/2dP+Zfj/AJHe0VwX9oap/wBBa6/KP/4mj+0NU/6C11+Uf/xNHs2H9nT/AJl+P+R3tFcF/aGqf9Ba6/KP/wCJo/tDVP8AoLXX5R//ABNHs2H9nT/mX4/5He0VwX9oap/0Frr8o/8A4mj+0NU/6C11+Uf/AMTR7Nh/Z0/5l+P+R3tFcF/aGqf9Ba6/KP8A+Jo/tDVP+gtdflH/APE0ezYf2dP+Zfj/AJHe0VwX9oap/wBBa6/KP/4mj+0NU/6C11+Uf/xNHs2H9nT/AJl+P+R3tFcF/aGqf9Ba6/KP/wCJo/tDVP8AoLXX5R//ABNHs2H9nT/mX4/5He0VwX9oap/0Frr8o/8A4mj+0NU/6C11+Uf/AMTR7Nh/Z0/5l+P+R3tFcF/aGqf9Ba6/KP8A+Jo/tDVP+gtc/wDfMf8A8TR7Ni/s6f8AMvx/yO9orjLfxBqlsy+ZIl4gPzLKoViPZlGP0NdPpmqW+q25ktyVZeJIn4aM+h/x6VLi0c9bC1KKu9UXKKKKk5QooooAKKKKACiio554raB5rh1jjQbmZjgAUDSbdkSUVyd34nu55Maei28POJJVy7e4HRfxyfYVnnUdVY5Oq3H4LGP/AGWrUGd8cBVkrtpHeUVwX9oap/0Frr8o/wD4mj+0NU/6C11+Uf8A8TT9my/7On/Mvx/yO9orgv7Q1T/oLXX5R/8AxNH9oap/0Frr8o//AImj2bD+zp/zL8f8jvaK4L+0NU/6C11+Uf8A8TR/aGqf9Ba6/KP/AOJo9mw/s6f8y/H/ACO9orgv7Q1T/oLXX5R//E0f2hqn/QWuvyj/APiaPZsP7On/ADL8f8jvaK4L+0NU/wCgtdflH/8AE0f2hqn/AEFrr8o//iaPZsP7On/Mvx/yO9orgv7Q1T/oLXX5R/8AxNH9oap/0Frr8o//AImj2bD+zp/zL8f8jvaK4L+0NU/6C11+Uf8A8TR/aGqf9Ba6/KP/AOJo9mw/s6f8y/H/ACO9orgv7Q1T/oLXX5R//E0f2hqn/QWuvyj/APiaPZsP7On/ADL8f8jvaK4L+0NU/wCgtdflH/8AE0f2hqn/AEFrr8o//iaPZsP7On/Mvx/yO9orgv7Q1T/oLXP/AHzH/wDE1at9f1W2K75ku0B+ZZVCsR7MoGPyNLkZMsvqJaNP+vQ7OiqWl6rb6rAXgykicSRP95D7/wCPQ1dqDglGUHyyWoUUUUEhRRRQAUUUUAFFRXNzDZ27z3MgjiQZZjXLXXie+uXP2JFtYccNIu6Q++Oi/Tn8KaTZ0UcPUrfDsddRXBnUdVJydWufwWMf+y0n9oap/wBBa6/KP/4mr5GdX9nT/mX4/wCR3tFcF/aGqf8AQWuvyj/+Jo/tDVP+gtdflH/8TR7Nj/s6f8y/H/I72iuC/tDVP+gtdflH/wDE0f2hqn/QWuvyj/8AiaPZsP7On/Mvx/yO9orgv7Q1T/oLXX5R/wDxNH9oap/0Frr8o/8A4mj2bD+zp/zL8f8AI72iuC/tDVP+gtdflH/8TR/aGqf9Ba6/KP8A+Jo9mw/s6f8AMvx/yO9orgv7Q1T/AKC11+Uf/wATR/aGqf8AQWuvyj/+Jo9mw/s6f8y/H/I72iuC/tDVP+gtdflH/wDE0f2hqn/QWuvyj/8AiaPZsP7On/Mvx/yO9orgv7Q1T/oLXX5R/wDxNH9oap/0Frr8o/8A4mj2bD+zp/zL8f8AI72iuC/tDVP+gtdflH/8TR/aGqf9Ba6/KP8A+Jo9mw/s6f8AMvx/yO9orgv7Q1T/AKC11+Uf/wATR/aGqf8AQWuf++Y//iaPZsX9nT/mX4/5He0Vxtt4h1S2ZfNdLyMfeEihHP0K8fpXT6bqdvqlr51uSCDh434aM+hFS4tHNWwtSirvYt0UUVJzBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHH+Ib43uqNaqT5FoQCMcPJjOffAIH1z6Cs2llcve3hbr9rnH5SMP6UldCVkfT04KEFFBRRRTLCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACnW94+mXiX0Z4j4lXs8fcfUdR7j3NNpCMjB5BoBpNWex6ECGUFTkEZBHelrO8Pknw3p245P2aMZPf5RWjXMfLzjyycewUUUUEhRRRQAVyPiS9a71M2YyILXBYZ+/IRnn2AI/E+1ddXnZlaa8vpHOW+23C59llZR+iirgtT0cvgnNzfQdRRRWx7IUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAOhu5NOukvYMlo/vqD/rE7r/AFHvXfo6yIrocqwyCO4rz7rXXeGiT4X07cSStui5PfAx/Ss5rqeZmEFyqfXY1KKKKyPICiiigAooooA4zX743+rPCrZt7RtoHZpMcn8M49jmqFDf6+c+s8hP4uTRXQlZH09OChBRXQKKKKZYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAU+1vjpV4l8G2xpxcDGd0ff8AEdR9Md6ZSEBlIYZBGCDRuJpSVpbHoYORkciiqmksX0WyZuS1vGT/AN8irdcx8xJcsmgooooJCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA89b/j7vP+vy4/9GtRQ3/H3ef9flx/6NaiulbH1S2CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA7Hw/8A8i3p/wD17p/KtGs7w/8A8i3p/wD17p/KtGud7nzVb+JL1YUUUUjIKKKKACvOIv8AX3v/AF/3X/o969HrziL/AF97/wBf91/6PetKe562Xfa+X6ktFFFanqBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV13hn/kWbD/riK5Guu8M/wDIs2H/AFxFZz2ODH/wl6/ozUooorI8QKKKKACiiigDz5v9dN/11f8A9CNJSt/rpv8Arq//AKEaSuk+qWwUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHa6N/yAbD/r2j/9BFXapaN/yAbD/r2j/wDQRV2uY+ZqfG/UKKKKDMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDz1v+Pu8/wCvy4/9GtRQ3/H3ef8AX5cf+jWorpWx9UtgooooAKKKKACiiqOq6hPp1ukltptzqDM+0x25QMox1O4gYoBuyuXqK53w34tPiVUlt9Gvre1cPtuZvL2EqdpGAxOcg9u1b6yxuzKjqzKcMAckfWgUZKSuh9FZOga2NasLi5eIQCG8ntsbs58uQpn8cZrTaWNZFRnUO33VJ5P0oBNNXQ+imPNHGCZJFQAgEswHWq813PHqlrbR2bSQTI7SXAcARFcYBXqc57dMUDuW6KYssbNhZFJ9AwoWWNpGRXUuv3lB5H4UAPopgljLhQ6liCQM8nFPoAKKKKACiiigAooooA7Hw/8A8i3p/wD17p/KtGs7w/8A8i3p/wD17p/KtGud7nzVb+JL1YUUUUjIKKKaZEWRY2dQ7AlVJ5OOuKAHV5xF/r73/r/uv/R716PXnEX+vvf+v+6/9HvWlPc9bLvtfL9SWiiitT1AooooAKKKKACiiigAorG1PxPY6T4j0rR7sSCbVN/kyADYpXHBPuSAPc0k/iiyg8YWvhwrI15cQNPuUfIijOMn1O0/lRcnnj3NqimebH5vl718zGdmecfSory7S0tpJGK7lRmVC2C2BnAoKLFFZ2jasuqeG9P1aVVt1vLWK4Ks3Cb1DYz+OKi1bW/7M1LR7VYRKNTuTBv3Y2YjZ8+/3cfjQTzK1zWooooKCiiigAooooAKKKKACuu8M/8AIs2H/XEVyNdd4Z/5Fmw/64is57HBj/4S9f0ZqUUUVkeIFFFFABRUL3ltHdpavPGtxIpZIiwDMB1IHepqdmgPPm/103/XV/8A0I0lK3+um/66v/6EaSug+qWwUUUUAFFU9X1KLRtFvNTuVZ4bOB53VPvEKCTj34rHsvGKT3dlDf6Tf6ct+QttNcKhjkYqWC5VjgkA4zQS5RTszpKKZ5sfm+XvXzMZ2Z5x64oaWNZFjZ1Dt91SeT+FBQ+iqNrq9peanfWEEmZ7FkSZT2LKGGPXg1B4g12PQLGG4ktprlp7iO2jihxuZ3OFHJA60C5klc1aKxNL8TRahqcmm3VldabepF54hulX5484LKVJBAPB571sCWMlgHUlRlhnoPegFJPYfRTUkSVA8bq6noynINIkscjMI3VipwwU5wfegY+impKkhYRurFThgpzg+9IkschYRurbThtpzg+9AD6KpX9+9vpc91p8H2+WIfLDHKq7znpuPAq00yRpulZYwAC25gMUBcfRTXkSOMu7qqDksTgfnQkiSDMbqw9jmgB1FFFABRRRQB2ujf8AIBsP+vaP/wBBFXapaN/yAbD/AK9o/wD0EVdrmPmanxv1CiiigzCiikZ1VlDMAWOFBPU+1AC0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVQvDq4uP9ASzMOB/rmYNn8Kv0VUXZ3sBk7vEP/PLTf++3/wAKN/iH/nlpv/fx/wDCtair9p/dQ7mTv8Q/88dN/wC/j/4Vg+N5vEcfgvUXjjto3CLta1kcyA7h93jrXaUVdOsoTUuVaMalZ3scR8PLnxpPZj/hLIIlt9n7qST5Zz9QOPzwa7eiipr1VVqOailfotgk7u5563/H3ef9flx/6Naihv8Aj7vP+vy4/wDRrUVa2PqFsFFFFABRRRQAUUUUAee+GnvI/gndvpe77YsF6YNvXf5kmMe+elVoE0S31Dwg/g542u5ZgLgwtl5Lfy2Mhmx3zt+9/FXpEUUcMYSFFjQdFUYFRQWFnazSTW1rDFLKcyOkYBf6kdaVjD2WiXax5Xok11HqMc2sxIvhyHXrxFIfrctO3lySD+4D8o/2iCe1OubSXVL7xNFf3WlWl+L11hub6Rlnt48DymjOeFAwRjqc16qbWAwtEYYzGzbmTaME5znH15qOfTrK6uI57m0hlmj+5I8YLL9CelKxPsNLXOFTRbPVfG3ipdYgS8aGxtQA4yoYxNlgOgPHXrUHhi5klk+HstxKzE6Ldl3duuFg5Jr0cQxiR3Eah5AA7Y5bHTNMFrbqqKIIwI1KIAg+VT1A9BxTsV7LW6/rW55xoSaNqmrajr2hDT7eaOGa30m1hKLJIwB3TMo5O4jAz0UZ71D4OsTdReHLu3vNJt7uMh7gq7fa7g7D5scgJyTnJOehWvSYdMsLeUSwWVvFIvRkiAI/GlTTrKK8a7jtIUuX+9MsYDN9T1pWEqO1zkfhpploujT6kYVa8kvrtDO3LBBO42g9hxnHrmu3pkcUcKbYkVFyThRgZPJp9UtDaEeSKQUUUUFBRRRQAUUUUAdj4f8A+Rb0/wD690/lUD6brBkYprpVSchfsqHA9Kn8P/8AIt6f/wBe6fyrRrGM3F6fkmfNVXapL1Zjf2Zrf/Qf/wDJRKT+zdc/6Dw/8A0raoq/bS7L7l/kZ8zMb+ztc/6Dq/8AgGv+NcV8Q/C/inV5tHTTLxrqaOSRvNRBAIOF5LA/5xXp1Fa0MXOjUVRJaeSKjNxdzH8MWGsabo6Qa/qa6jcjH7wR7do9M/xfU1yEX+vvf+v+6/8AR716PXnEX+vvf+v+6/8AR71nzuc3J9T08vd+d+n6ktFFFUeoFFFFABRRRQAUUUUAcB44019V8Y6Xb2//AB8rpl3NbH+7MkkDof8AvpRVTSzdXvjDQdcvbZra61VryVYZBhoo1iRI1P4At9XNejmKMyrKUUyKCFYjkA9Rn8KVo0aRXZFLpnaxHK564pWMXSvLmueQD7F/wgMd4HX/AITH7eOd3+k/aPPwVI67dvbptrYuV0a51jxc/iloDfQtstVuGwUt/KBQxD3YtyvOa9B+wWf237Z9lh+04x53ljfj0z1omsLS4uY7ie1hkmi/1cjoCyfQ9qViVRaPLYvNkt/A8F39iNg2gIY11AkQNPsj644Lbc4z71oLaPp0vhGOW8tbiE65OYGtnzHGjRS4jUn0OQPyr0OaxtLm1FrcW0MtuAAInQFQB046UfYbQwxRfZovLhYPEmwYRh0IHYiiwKjbr/Wn+RPRRRVHQFFFFABRRRQAUUUUAFdb4aGfC9iM4/cjkVyVdd4Z/wCRZsP+uIqJ7HBj/wCEvX9GN/sa6/6Dmof+Q/8A4ij+xrv/AKDl/wDlF/8AEVrUUvay/pI8W7Mn+x7v/oO3/wD3zF/8RS/2Ref9By+/75i/+IrVoo9rLy+5BdnmXjjwBrniPX9Lax1KQxwRtvupyqmIkjG0IASeK73Q9OuNK0iG0vNQm1GWMYM8wG4/l/XJrQorWriqlWlGlK1o+RTm2rHnzf66b/rq/wD6EaSlb/XTf9dX/wDQjSUj6dbBRRRQBz/jz/knfiD/ALB0/wD6LNZ+j+HNRvodGutc1Zbq3sljuLe2htxEA4TCljkk4DH05rrpI0ljaOVQ6MMMrDII9KUAKoCjAAwAO1Kxm4Jy5meQv9jPgG6vJ2jHjUXb/db/AEkXfm4VFHXbjAAHy7a1/EBtNI8R3es3I07Vt81ss1nI4F1auNqjyuuRkhtuB35r0A2Fmb0XhtYTcgYE3ljeB9etJJp1lLeJdyWkL3KfdmaMFl+h60rGfsXbf+u5xWhWVhb/ABE8WtDBZx6n58Uln5oAY7rcFiO+C27OPepfGa6vJoWkrePaQXra7aCKSBWdF+cYJBxnnPFdk1laveJdvbxNcxjakxQb1HoD1qSSJJdvmIr7WDLuGcEdD9adivZ+64nGav4eurfR9c1nWNS+3340i4t4jHCIkijKljhQTkkgck9qx7jS7HTvBvhdniEWn3s1sdXnJOZVMbFfMbrt8wrnPGDjpXprosiMjqGVhggjIIpjQRNB5LRoYtu3YV+XHpiiwOknseZaqzWcnitPBBUWa6Sjyi0OUjudzZ8vHAbyuSB3C960tRTRbTwNqUngQ2p1A6aSjWrAzNHxljjktgnk85967m2tLeygENnBHBEOiRoFH5Cm22n2dm8j2lrDA0py5jjClj7460WF7J/109Dz7StNtHliurTU9HsLX+zZkm/s2U+Y8bKMSNk9UPOTzyag02Cwt7G/8OzXGmweZpJxrmnuBmMMqZlHZiWBznn5ulejwabZWskkltaQRPL/AKxkjAL/AFx1pLfTbG0WRbWzghEpzII4wu/6460WF7E8y1K4htvBXijS47TT454NPjka70s/uplJIXcP4X4PGTwc10FxpNjq/wAV76LU7dLqKPSIWWKXlMmSQZ29Ccd662DTLG2t3t7ezgihkOXjSMBW+o71OIoxMZQi+YRtL45I9M0WGqXf+t/8zyWwnC+E/Bj3u29t457qNrO4kVUlC7whLP8ALlAvAPXPHSu28B6VDpmi3DRLaq11dSzFLV1dYlZiVj3DrtB/Wpdf8NSahc2FxYG0C2YkH2S6h3wPvx82BjDDBwf9o+tSeGfDY0KS/uHMAnv5FeSO1i8uGPau0BVz+JPeklqTCm4z/rsb1FFFUdIUUUUAdro3/IBsP+vaP/0EVWn0/V3uJHh1sxRsxKx/ZUO0eme9WdG/5ANh/wBe0f8A6CKu1jGTi9PyufM1Hab9TG/s3W/+g9/5JpR/Zuuf9B5f/ANf8a2aKr20uy+5f5EczMb+ztb/AOg6v/gGv+Ncl8RPDXibVtJsYNPvTeTLeK4CRrD5eEb5ywPv+tejUVrRxU6VRTSWnkiozadzB8I6Zrml6OsHiLVF1GcAbSExsHoW6t9TW9RRWFSbqTc317aEt3dwoooqBBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeet/x93n/X5cf+jWoob/AI+7z/r8uP8A0a1FdK2PqlsFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB2Ph/8A5FvT/wDr3T+VaNZ3h/8A5FvT/wDr3T+VaNc73Pmq38SXqwooopGQUUUUAFecRf6+9/6/7r/0e9ej15xF/r73/r/uv/R71pT3PWy77Xy/UlooorU9QKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACuu8M/8izYf9cRXI113hn/AJFmw/64is57HBj/AOEvX9GalFFFZHiBRRRQAUUUUAefN/rpv+ur/wDoRpKVv9dN/wBdX/8AQjSV0n1S2CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA7XRv+QDYf9e0f/oIq7VLRv8AkA2H/XtH/wCgirtcx8zU+N+oUUUUGYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHnrf8fd5/wBflx/6NaipLuPyNVvoTwy3Duf+BneP0ao66FsfUxd0mFFFFMYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUyV/Lhd8FtoJAHf2oGdp4f/AORb0/8A690/lWjVTSrVrLR7O1kILwwojEdyAAat1zM+YqtOpJruFFFFBmFFFFABXnEX+vvf+v8Auv8A0e9ej1wN5bi01a+gz/y8PKPpId/82I/CtKe56mXNXkvT+vxI6KKK1PWCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArrvDP8AyLFh/wBcRXHyOIomduigk12+jWj2Oh2VrLzJFAiuR/exz+tZ1Njz8wa9kl5l2iiisjxQooooAKKKKAPPm/103/XV/wD0I0lOnRob+7hkGGjnfj2J3KfyIptdK2PqVqkwooooGFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFRzSGKF3VC7AfKi9WPYD3J4oGdzo3/IBsP+vaP/0EVdqCygNtp9vAesUSofwGKnrmPl5tObaCiiiggKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDC8RaPJdFb2yG6eNdrx/89E6/mMnH1NcwjhwcdQcEEYIPoR2r0SqF9oljqD+ZPDiXGPNjO1vzHX8auMraM9HDYz2ceSexxlFdC3hCAn5b66UemVP81pP+EPi/6CN3+Sf/ABNXzo7vrlDv+Bz9FdB/wh8X/QRu/wAk/wDiaP8AhD4v+gjd/kn/AMTRzoPrlDv+DOforoP+EPi/6CN3+Sf/ABNH/CHxf9BG7/JP/iaOdB9cod/wZz9FdB/wh8X/AEEbv8k/+Jo/4Q+L/oI3f5J/8TRzoPrlDv8Agzn6K6D/AIQ+L/oI3f5J/wDE0f8ACHxf9BG7/JP/AImjnQfXKHf8Gc/RXQf8IfF/0Ebv8k/+Jo/4Q+L/AKCN3+Sf/E0c6D65Q7/gzn6K6D/hD4v+gjd/kn/xNH/CHxf9BG7/ACT/AOJo50H1yh3/AAZz9FdB/wAIfF/0Ebv8k/8AiaP+EPi/6CN3+Sf/ABNHOg+uUO/4M5+iug/4Q+L/AKCN3+Sf/E0f8IfF/wBBG7/JP/iaOdB9cod/wZz9FdB/wh8X/QRu/wAk/wDiaB4PhzzqF2f++P8A4mjnQfXKHf8AA54kKCWIAHUmtTQtIe/uY7y5QraRMHjVhzKw6H/dHX3OPx2LXw1p1u6u6PcOpyDM24A+uOla9TKfY5a+OTjy0/vCiiiszygooooAKKKKACsPxDo73gS8s1BuYl2snTzU64+o6j6n1rcopp2ZpTqSpSUonnauHzjIIOCpGCp9CO1Ors77RbHUH8y4hxLjHmodrfmKzW8IQE/JfXSj0yp/mtaqaPYhjqUl72hz1FdB/wAIfF/0Ebv8k/8AiaP+EPi/6CN3+Sf/ABNHOi/rlDv+DOforoP+EPi/6CN3+Sf/ABNH/CHxf9BG7/JP/iaOdB9cod/wZz9FdB/wh8X/AEEbv8k/+Jo/4Q+L/oI3f5J/8TRzoPrlDv8Agzn6K6D/AIQ+L/oI3f5J/wDE0f8ACHxf9BG7/JP/AImjnQfXKHf8Gc/RXQf8IfF/0Ebv8k/+Jo/4Q+L/AKCN3+Sf/E0c6D65Q7/gzn6K6D/hD4v+gjd/kn/xNH/CHxf9BG7/ACT/AOJo50H1yh3/AAZz9FdB/wAIfF/0Ebv8k/8AiaP+EPi/6CN3+Sf/ABNHOg+uUO/4M5+iug/4Q+L/AKCN3+Sf/E0f8IfF/wBBG7/JP/iaOdB9cod/wZz9FdB/wh8X/QRu/wAk/wDiaP8AhD4v+gjd/kn/AMTRzoPrlDv+DOfpCQBknA9TXQjwfD31C7P/AHx/8TVu28MadAwaRHuWByPObcAfp0o50KWOopaO5i6JpL6jcx3U6FbOJgyhh/rmHT/gIPPv9K7GgDA4orJu7PIr15VpXYUUUUjAKKKKACiiigDn/EWjSTyC/sl3zKu2WMf8tFHTHuMn6/lXNo6uMqfqDwR7EV6JWffaHYX8hkmh2zEY82M7WP1x1/GrjK2jPSw+M5I8lTY42iuhbwhAT8t/dKPT5D/7LSf8IfF/0Ebv8k/+Jq+dHb9cod/wOforoP8AhD4v+gjd/kn/AMTR/wAIfF/0Ebv8k/8AiaOdB9cod/wZz9FdB/wh8X/QRu/yT/4mj/hD4v8AoI3f5J/8TRzoPrlDv+DOforoP+EPi/6CN3+Sf/E0f8IfF/0Ebv8AJP8A4mjnQfXKHf8ABnP0V0H/AAh8X/QRu/yT/wCJo/4Q+L/oI3f5J/8AE0c6D65Q7/gzn6K6D/hD4v8AoI3f5J/8TR/wh8X/AEEbv8k/+Jo50H1yh3/BnP0V0H/CHxf9BG7/ACT/AOJo/wCEPi/6CN3+Sf8AxNHOg+uUO/4M5+iug/4Q+L/oI3f5J/8AE0f8IfF/0Ebv8k/+Jo50H1yh3/BnP0V0H/CHxf8AQRu/yT/4mj/hD4v+gjd/kn/xNHOg+uUO/wCDOforoP8AhD4v+gjd/kn/AMTQPB8OedQuz7fJ/wDE0c6D65Q7/gc8zBVJYgAdSa1tA0iS8uYr65Vkt4jvhVuDI3ZiPQdvU89q17Xw3p1s6uyNcOpyrTNuwfUDpWtUynfY5a+OTjy0/vCiiiszygooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKydZ1ltPZIbdFeZl3Et0UdM+/f8qzqVI0o889jSnTlUlyx3NaiuT/4STUP+mH/fs/40f8JJqH/TD/v2f8a4v7SoeZ1/UK3kdZRXJ/8ACSah/wBMP+/Z/wAaP+Ek1D/ph/37P+NH9pUPMPqFbyOsork/+Ek1D/ph/wB+z/jR/wAJJqH/AEw/79n/ABo/tKh5h9QreR1lFcn/AMJJqH/TD/v2f8aP+Ek1D/ph/wB+z/jR/aVDzD6hW8jrKK5P/hJNQ/6Yf9+z/jR/wkmof9MP+/Z/xo/tKh5h9QreR1lFcn/wkmof9MP+/Z/xo/4STUP+mH/fs/40f2lQ8w+oVvI6yisfRtbOoStb3Kqk4Xeuzo69D9MZH51sV20qsKseaGxyVKcqUuWQUUUVoZhRRRQAUUUUAFFFFABRRRQAUVHFcRTmQROrGNijgH7pHY1JSTT2G01owooopiCiiigAoorn9T8QywXj29mifuzh3kBOT6ACsa1aFGPNM1pUZ1pcsToKK5P/AISTUP8Aph/37P8AjR/wkmof9MP+/Z/xrk/tKh5nV9QreR1lFcn/AMJJqH/TD/v2f8aP+Ek1D/ph/wB+z/jR/aVDzD6hW8jrKK5P/hJNQ/6Yf9+z/jR/wkmof9MP+/Z/xo/tKh5h9QreR1lFcn/wkmof9MP+/Z/xo/4STUP+mH/fs/40f2lQ8w+oVvI6yiuT/wCEk1D/AKYf9+z/AI0f8JJqH/TD/v2f8aP7SoeYfUK3kdZRXJ/8JJqH/TD/AL9n/Gj/AISTUPS3P/bM/wCNH9o0PMPqFbyOsoqjpOpDU7UybNkiNtkXsDjPHtV6u6E4zipR2ZxThKEnGW4UUUVZIUUUUAFFFFABRRRQAUUVHDcRXG/yZFfy3KOAfusOoNK62HZ2uSUUUUxBRRRQAUUUUAFFczd+Jbg3DrZRxrEpwGkBJb369Kh/4STUP+mH/fs/4158swoJ2udywNZq51lFcn/wkmof9MP+/Z/xo/4STUP+mH/fs/40v7SoeY/qFbyOsork/wDhJNQ/6Yf9+z/jR/wkmof9MP8Av2f8aP7SoeYfUK3kdZRXJ/8ACSah/wBMP+/Z/wAaP+Ek1D/ph/37P+NH9pUPMPqFbyOsork/+Ek1D/ph/wB+z/jR/wAJJqH/AEw/79n/ABo/tKh5h9QreR1lFcn/AMJJqH/TD/v2f8aP+Ek1D/ph/wB+z/jR/aVDzD6hW8jrKK5MeJNQByVt29thGf1rotOvk1CyWdFKkkhlP8JHUVvRxdKs+WD1Ma2FqUVzS2LVFFFdRzBRRRQAUUUUAFFFFABRRRQAUVHFPFPv8l1fy3KNg/dYdQakpJp6obTWjCiiimIKKKKACiiuf1PxDLBePb2SIfLOHdwTz6AVjWrQox5pmtKjOtLlidBRXJ/8JJqH/TD/AL9n/Gj/AISTUP8Aph/37P8AjXJ/aVDzOr6hW8jrKK5P/hJNQ/6Yf9+z/jR/wkmof9MP+/Z/xo/tKh5h9QreR1lFcn/wkmof9MP+/Z/xo/4STUP+mH/fs/40f2lQ8w+oVvI6yiuT/wCEk1D/AKYf9+z/AI0f8JJqH/TD/v2f8aP7SoeYfUK3kdZRXJ/8JJqH/TD/AL9n/Gj/AISTUP8Aph/37P8AjR/aVDzD6hW8jrKK5P8A4STUP+mH/fs/40f8JJqH/Tv/AN+z/jR/aNDzD6hW8jrKKz9I1QanbuWUJNGQHUHI56Eex/pWhXdCcakVKOzOOcJU5OMtwoooqyAooooAKKKKACiiigArkfEn/If/AO3aP/0J666uR8Sf8h//ALdo/wD0J683Mv4HzPQy/wDjfIzKKKK+cPdOeuvHGi2d7dW00lzus32XDpayOkZwDywBHQg1u29xDd2sVxbSLLDKgeN1OQykZBFeYXGqa7o9x4xvdLWz+xR6mv2mSVGeSFTFEGkCjhgoOcexrVuLGygs9I8Nab9r1B7XTVlXy7w28Xl8KJXYHkkg4Az3rrlRjZW/rQ5o1Xd3/rU76ivLdL8TXWl+F/CniPV7yWW3MNzaXpLkh8BmRz6tmHGf9qpNLv8AUFuNP8L3l5cNfy6hBdyuznd5Bh85xn+75ismPQ0nh5K+u36bjVdO2h6Pc3ttZtAtzMsbXEohiDfxuQSAPfANT1xXxA06C91Lwx57zKG1VYj5czJwY3PYjnIHPWs6/F/qXjDV9Mjhu7mHTreBLVIr/wAjy9yZMp5Bc54ycj5amNJSinf+r2G6jTasejVC13At6lm0qi4kjaVI+5VSoY/gWX86848RapreiWelSS3zLqdzp3k6miHekCAgG7GOAVLfjn2rRfRLN/iXpSG4upI00WR0f7U43lJYQDkHnI5PY9TT9ikrt9/wD2t3ZLt+J3lFFFcxuaPh7/kPx/8AXF/5rXYVx/h7/kPx/wDXF/5rXYV9Hlv8D5nhZh/FXp/mFFFFekeeFFFFAGRrGvrpNzDB9lkuHlRnGwgYAIHf61Q/4TH/AKhdx/32n+NQeK/+Q7Zf9e0n/oSVlZHrXz+JxleFaUIy0Xkux7uHwtGVGMpRu35vuzc/4TH/AKhdx/32n+NH/CY/9Qu4/wC+0/xrDyPWjI9a5/r+J/m/BG31PD/y/i/8zc/4TH/qF3H/AH2n+NH/AAmP/ULuP++0/wAaw8j1oyPWj6/if5vwQfU8P/L+L/zCC+u7fVrnVLWNo2mlLPbu3EiccHHf0NdvpupW+qWa3Fs3HRkP3kPcEetcTmr3hi2uZ9XN7asYrRQVlbtOewA9vX8K1wOIqRq8m6f9X/zJxlGFSm5vRxX9L/I7Oiiivoz54KKKKACuEvf+Qld/9d3/APQjXd1wl7/yErv/AK7v/wChGvIzT4I+p6mXfFIhqvf3sGm6dcX14+y3tomllbGdqqMk4+gqxWF44/5J/wCIP+wbcf8Aotq8SKvJI9eTtFs245FlhSRDlHUMp9QadXBtavq3jqz024vLuOxGgpM8EExjWRvM25JHPfsR0FZ1vc3k/hPw7bS6ndR7tflspJ1lxI8S/aFClvooGev41r7Hz/rX/Iy9r5f1/TPTaK8u16e40OHxjp2k3t0bW30qK6QtOztbTMWBAYnIyFBxmuhv7t5vHXh2yW6fybjT7ppo0kI3fLHhjj6nBodF73/q1wVXpb+r2OqtbuC9hMtrIsqLI8ZZezIxVh+DAj8KoXPiXS7SPVHnnKrpIU3fyE+WGXcPrwe1YXw202C10CW4jedpXvbuNxJOzgbbmQDgnAPqeprB8Q/8ePxL/wCucH/ogU40ouo49v8ANITqSUFLv/lc7bTfFmk6pfiygmkiumUssNxC8TOB1KhgM/hW1XH+OHil1LwxBAVa/wD7YieNVPzCMBvMP+7t6/hVO08/RvFay6/9puPt2oPHZ6hDdMYiGzsheLOFwOOh5HWl7NNXX3D9o07M7yiiiuc3Oi8Lf6u6/wB5f5Gt+sDwt/q7r/eX+Rrfr6nBf7vH+up87jP48v66BRRRXYcgVj6v4gXSbuK3+yS3DyIX+QgYAOO9bFcj4p/5D1t/17N/6EK48bVnSouUHrodmDpwq1eWautSx/wmP/ULuP8AvtP8aP8AhMf+oXcf99p/jWHketGR614f1/E/zfgj1/qeH/l/F/5m5/wmP/ULuP8AvtP8aP8AhMf+oXcf99p/jWHketGR60fX8T/N+CD6nh/5fxf+Zuf8Jj/1C7j/AL7T/GsK0vbyz1S61K2RkM07O9u7DEiHt6A+9LketLmsqmJrVGnKW2xrTo0qaajHffc7fTtRt9Us1uLVsqeGU9UPcEetWq43wvbXM2rNe2zGKzAKyHtOe2B7ev4V2VfR4StKtSU5Kz/PzPBxVGNGq4xd/wBPIKKKK6jlCiiigDzxP9Wv0FOpqf6tfoKdXxR9aFFFFAFTTdTtdXszdWEnmRCR4txUj5kYqw59wat1ynw6ZR4UYEjP9oXvGf8Ap5krmZJp5/Aup+LJtTuoNZt553jjE5CQtHIVW38vOCCAAcjJ3Zro9jebSfWxh7W0U32ueo1UbUFXV00/yZy7wmYSiM+WACBgt689K8+8RTXmoa9rVpJHqctz/Z0B06OxkdVt5nV87ypAB3ActxgVqw280PjnTtFmuJ/Ibw/MZkE7nL+bGC27Oc8nBzkUexSV2/6sHtbvRHYWd5b6hZx3VnKs0Eo3JIvRhU9eYeGdFuZfhJpLaNcyC6uRDJPDJduonVSd0Stn93kZ+76V2HhC8trjTrm3tobq2ks7hoZ7e6lMjQvgNgMScrhgRz3pVKajez2Y4VHK11ujfooorA2Cun8Lf8g2b/ruf/QVrmK6fwt/yDZv+u5/9BWvRy7+P8mcOO/gs2qKKK+kPACiiigDG1fxCmlXsdt9kluHePzPkIGBnHeqX/CY/wDULuP++0/xqp4o/wCRlt/+vQ/+h1nZHrXz2IxteFaUYy0Xkj3qOEoSpRlKN213Zuf8Jj/1C7j/AL7T/Gj/AITH/qF3H/faf41h5HrRketYfX8T/N+CNfqeH/l/F/5m5/wmP/ULuP8AvtP8aP8AhMf+oXcf99p/jWHketGR60fX8T/N+CD6nh/5fxf+YWt/d2eqXOpW0bL58zPJbM331J/IN713Gnajb6nZrcWrZU8EHqp7gjsa4jNaHha1uZtUe+tmMVngrIe07dsD29fwrXAYipGp7PdP8PP/ADIxtGFSm5vRr+rf5f5bdjRRRX0Z8+FFFFABXB3f/IQuv+viT/0M13lcHd/8hC6/6+JP/QzXkZp8EfU9TLvikZmsavZ6FpcuoalI0dvEVDMqljlmCjgc9SKq6Z4p0vVr42VtLKl0E8wQ3ELxMyjqQGAyOR0rI+KJcfD688oAv59ttDHAJ+0R4zVi00jWdQ8S2Wr6/wDY7cafHKtvBaMz7mkABLMwHAA4AHevIjCPs+Z+f6HpuUuflXkdPRXlMM9/Y/Cmx1pL67n1DUWt7ea4ecjy4mlCnbn5VOON3XJyTVrVJPEHhrQ9evrK3lsbNdPBjWa8+0tFNvwZFySQNrEntlav6vrZPrYn22l7dLndXutwWOu6ZpciO02o+b5bLjavlruOfwNWNPvl1G1M6QzQgSOm2eMo3ysRnB7HHFcLNo9ppPxE8Hi0u7i4MiXZdp7hpd58ofPyTjPtxUSX95eaToNhcX08FvqOtX0NzcLIVcoks5SIN1G7aq8dhgUOimlb+t/8g9q03f8Arb/M9Cuby3s1iN1KsYmlWGPd/E7HAH1NM+3qdXOn+TNvEAn83yz5eN23bu6buM49K4rxjoFlBZaBbRTXZh/tyBCDdyEqH6jOc9hj0zx1p+uaheaHreqppssrrY+GfOgjdy43rI4DHPU8Dk9cVKpKSVnuN1Gnqd5RXn0cZ0Wfwneadqd1dz6pcJDdrLcNItyjRMzSbScLtIB4x1xWbfpdDwjrmvnUr43un6xcC1xOQkSLdldm0cEEZHOeOO1NULvcTrW6HqdFcH4kE+l+IrrWtW+1XGjoIQklpdsjWJH3t0YI3BiQSeTjtXdg5AI6GspQ5Un3NYyu2ja8J/8AIQ1D/rlD/OSuorl/Cf8AyEdQ/wCuUP8AOSuor6LL/wDdo/P82eHj/wDeH8vyQUUUV3nCFFFFABRRRQAUUUUAFcl4kB/t7PY2yf8AoT11tUdS0mDU1UyFo5E+7IvUD09xXJjKMq1LljudWFqxpVOaWxxlFdB/wig/5/n/AO/Yo/4RQf8AP8//AH7FeH9QxH8v4o9j65Q/m/BnKxaZZQm78u2jH2xy9wCMiUlQuSD7ACqE3hHQ50tEk09CtnH5UI3MNqf3OvK+xyK7n/hFB/z/AD/9+xR/wig/5/n/AO/YqlgsUtl+JLxWGe7/AAf+Rxk3hvR7jRl0mbT4XsEbetuV+UHduyPxJqc6RYHWV1Y2sZv1h8gXGPmEec7fzrrP+EUH/P8AP/37FH/CKD/n+f8A79ij6liu34oPreG7/g/8jktU0ix1qzFtqdus8QcOoJIKsOhBHIPuKq3vhbRtQMBu7JXeCMRI4dlbYP4SwOSPY12//CKD/n+f/v2KP+EUH/P8/wD37FCwWKWy/FA8Vhnu/wAH/kckmj6fHJI62kW6WBbd8jOYlzhMH+Hk8VWn8MaRcRWMctmpGnjbbEOwMY44BBzjgce1dt/wig/5/n/79ij/AIRQf8/z/wDfsUfUsUun4oPrWG7/AIP/ACOforoP+EUH/P8AP/37FH/CKD/n+f8A79ip+oYj+X8UP65Q/m/BlDw9/wAjBH/1wc/qtdhVDTdJg0wMYy0kj8NI3XHoPQVfr28HRlRpcstzycXWjVqXjsFFFFdhyBRRRQBTvdJsdSdGvbZZmQEKSTwDVb/hGNG/58I/zP8AjWrRWUqFKTvKKb9DaNerFWjJperMr/hGNG/58I/zP+NH/CMaN/z4R/mf8a1aKn6vR/kX3If1mv8Azv72ZX/CMaN/z4R/mf8AGj/hGNG/58I/zP8AjWrRR9Xo/wAi+5B9Zr/zv72cTZ+HXvNYvYAjW+mxXB5B5kGB8q+3qa7OKKOCFYoUVI0GFVRgAU+iow+Gp0L8u7LxGJnXa5tl/V/UKKKK6jlCiiigArhb4Y1O7z/z3f8AnXdVlahoEF9cGdJGglb7xUAhvcj1rgx2HnWglDdHdg60KU3z9Tk6iu7WC+s5rS7jEsE6NHJG3RlIwR+VdL/wig/5/n/79ij/AIRQf8/z/wDfsV5H1DE/y/ij0/rmH/m/BnKpptnHfLepAq3KwC3Eg6iMHO36ZrE1zwlbX9vpVpa20K2dtqf2y4ibOGBSTdj3LSZr0X/hFB/z/P8A9+xR/wAIoP8An+f/AL9iqjg8VF3S/FEvFYZqzf4P/I4yy8O6Tp+n3Fja2Ma29znz0bLebkYO4nJPHHNR6d4V0TSbiKewsI4poQypLksyhsZGSenA47V2/wDwig/5/n/79ij/AIRQf8/z/wDfsUfU8V2/H/gh9aw3f8H/AJHH2Whadp1/c3llbCGe6YtMVY4Yk5JxnAJPPFLPoem3KX6T2cbrqIAuwc/vgBgZ/Diuv/4RQf8AP8//AH7FH/CKD/n+f/v2KX1LFXvb8UP63hrWv+D/AMji9N8N6Po9w0+nWEUMzDaZeWfHpuOTj2pkPhbRbfUxqENhGtwHMinJ2q56sFzgE5PIHeu3/wCEUH/P8/8A37FH/CKD/n+f/v2Kf1PFdvx/4IvrWG7/AIP/ACOforoP+EUH/P8AP/37FKPCi55vXx7Rio+oYj+X8UV9cofzfgxfCvMV1/vqP0rfqvY2MOn2whtxgZyzHqx9TVivoMPTdKlGD3R4uIqKpVckFFFFbmAVTvdIsNRkV722WZkGFJJ4FXKKmUYzVpK6KjOUHeLszK/4RjRv+fCP8z/jR/wjGjf8+Ef5n/GtWisvq9H+RfcjX6zX/nf3syv+EY0b/nwj/M/40f8ACMaN/wA+Ef5n/GtWij6vR/kX3IPrNf8Anf3syv8AhGNG/wCfCP8AM/41zmn+HZLzVb2FkaDTY7lxwTmQf3R6D1NdxRWNTBUaji+VK3Zbm1PHVoKSu3fu9hsUSQRLFCgREGFVRgAU6iiu3Y4twooooAKKKKAPPU4QA9hS10934aguLhpYJmg3ncyhQRnuag/4RQf8/wA//fsV81LL66dkr/M+gWNoNXbsc/RXQf8ACKD/AJ/n/wC/Yo/4RQf8/wA//fsVP1DEfy/iivrlD+b8GcFF4L8Pw3guodNRJhL5wZXcfPu3ZxnHXmppfCmiT6r/AGjLp0TXJcSFucM46MV6FvcjNdv/AMIoP+f5/wDv2KP+EUH/AD/P/wB+xV/U8X/T/wCCR9Zwvf8AD/gHlGs+GLm58TX19JpMepLdLGsEgvWtzCqrjawHUbizZ5PzY7Vt+HPDv9k6fYHUZBeana2xt2vGJLFC24rk9RkDrzxXef8ACKD/AJ/n/wC/Yo/4RQf8/wA//fsVUsLinHlt+P8AwRLEYZO/N+D/AMjg18G6AsE8K6cixzSCVlDMArDPK8/Kfmb7uOprR03SrLSLX7Pp0Cwxli7AEksx6kk8k+5rq/8AhFB/z/P/AN+xR/wig/5/n/79ioeCxT0a/EpYrDLZ/g/8jn6K6D/hFB/z/P8A9+xR/wAIoP8An+f/AL9ip+oYj+X8UV9cofzfgzn66fwuP+JZKfWdsfkKhHhRc/NeyEd8IBW3a2sVnbJBbrtReg/rXdgsJVpVOeehx4vFU6lPlg7ktFFFeyeSFFFFAFK90ew1GVZL22WV1XarEngelV/+EY0b/nwj/M/41q0VjKhSk7yim/Q2jXqxVoyaXqzK/wCEY0b/AJ8I/wAz/jR/wjGjf8+Ef5n/ABrVopfV6P8AIvuQ/rNf+d/ezK/4RjRv+fCP8z/jR/wjGjf8+Ef5n/GtWij6vR/kX3IPrNf+d/ezibDw5JeapdxPG0GmxXLgDJzKM/dHt6mu0jjSGJY4lCIowqqMACnUVOHw0KCfLuysRiZ12ubZBRRRXScwUUUUAFcJecajdg9ftEn/AKETXd1lajoMF/OZ1kaGVvvFQCG+o9a4Mdh51oLk3R3YOvClJ8+zOLv9PtdTs2tb+FZ4GZWKN0JVgwP4EA1YroP+EUH/AD/P/wB+xR/wig/5/n/79ivI+oYna34o9P65h/5vwZySaPp8ejjSltIvsATy/s7Lldvpg1BY+G9J063nhtbNfLuF2SrIxk3rz8p3E8cnj3rtP+EUH/P8/wD37FH/AAig/wCf5/8Av2Kf1LFdvxQvrWG7/g/8jhtP8I6Fpd1Fc2OnRxzwZ8qQksyAjBAJPAx26VYm8P6VcaW2nTWMT2hkaXyiOjsxcsD1B3MTketdj/wig/5/n/79ij/hFB/z/P8A9+xTeDxTd2vx/wCCL61hkrX/AAf+RxH/AAi2jHR20s2Km0eQSshZiS4xht2c54HOe1WbbR7C0lWWC2USLbi2DsSx8oEkKSeoyTXXf8IoP+f5/wDv2KP+EUH/AD/P/wB+xS+pYp9PxH9aw3f8H/kcRp/hbRdKvftdhp8UM2CFYZOwHqFBOFB9sVYfRNNk0+4sXtIza3MjSzRc4d2bexP1bmuv/wCEUH/P8/8A37FH/CKD/n+f/v2KHgsU3dr8Q+tYZK1/wf8AkcTeeF9Gv9Q+23liks5KliSdrlehZc4bGB1Hataug/4RQf8AP8//AH7FH/CKDvev/wB+xQ8DiXuvxQLF4dbP8H/kQ+Ewft+oNjjy4Rn3zJ/iK6eq1hYQ6db+VBk5O5mY8sfU1Zr3MLSdGioPf/g3PHxNVVarmtv8lYKKKK6TnCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA/9k=\" alt =\"Submit\" style='width: 800px;'>","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"*In this part, we will explore the competition data to understand what we are trying to predict in order to preprocess the data correctly.*","metadata":{}},{"cell_type":"markdown","source":"## Description","metadata":{}},{"cell_type":"markdown","source":"A description of the data and a *data dictionary* are available at the following adress: [data dictionary](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/data).","metadata":{}},{"cell_type":"markdown","source":" ## Loading","metadata":{}},{"cell_type":"markdown","source":"The data is constituted of 5 *.csv* files.\n\n* *Loads the data:*","metadata":{}},{"cell_type":"code","source":"# Input competition data path\ndata_input_path = '../input/nbme-score-clinical-patient-notes'\n\n# Loads the data using Pandas\nfeatures = pd.read_csv(f'{data_input_path}/features.csv')\npatient_notes = pd.read_csv(f'{data_input_path}/patient_notes.csv')\ntest = pd.read_csv(f'{data_input_path}/test.csv')\ntrain = pd.read_csv(f'{data_input_path}/train.csv')\nsample_submission= pd.read_csv(f'{data_input_path}/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:33.613376Z","iopub.execute_input":"2022-04-28T00:45:33.613706Z","iopub.status.idle":"2022-04-28T00:45:34.359103Z","shell.execute_reply.started":"2022-04-28T00:45:33.61367Z","shell.execute_reply":"2022-04-28T00:45:34.358348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quick Peak","metadata":{}},{"cell_type":"markdown","source":"*Let's take a look a the actual dataframes !*","metadata":{}},{"cell_type":"markdown","source":"### Train Dataset","metadata":{}},{"cell_type":"markdown","source":"We print the *train* head out:","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.36247Z","iopub.execute_input":"2022-04-28T00:45:34.362779Z","iopub.status.idle":"2022-04-28T00:45:34.380674Z","shell.execute_reply.started":"2022-04-28T00:45:34.362745Z","shell.execute_reply":"2022-04-28T00:45:34.380011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The *case_num* corresponds to a single \"patient\" with its unique caracteristics and history.","metadata":{}},{"cell_type":"code","source":"train.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.382058Z","iopub.execute_input":"2022-04-28T00:45:34.382325Z","iopub.status.idle":"2022-04-28T00:45:34.432357Z","shell.execute_reply.started":"2022-04-28T00:45:34.382291Z","shell.execute_reply":"2022-04-28T00:45:34.431547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Patient notes","metadata":{}},{"cell_type":"markdown","source":"We print the *patient_notes* head out:","metadata":{}},{"cell_type":"code","source":"patient_notes.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.434035Z","iopub.execute_input":"2022-04-28T00:45:34.434719Z","iopub.status.idle":"2022-04-28T00:45:34.444404Z","shell.execute_reply.started":"2022-04-28T00:45:34.434682Z","shell.execute_reply":"2022-04-28T00:45:34.443506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Each *pn_history* is a note written by the medical students taking the test,\n* *pn_num* ids each of these *pn_history* notes.","metadata":{}},{"cell_type":"code","source":"patient_notes.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.44585Z","iopub.execute_input":"2022-04-28T00:45:34.446115Z","iopub.status.idle":"2022-04-28T00:45:34.510987Z","shell.execute_reply.started":"2022-04-28T00:45:34.446079Z","shell.execute_reply":"2022-04-28T00:45:34.510185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features","metadata":{}},{"cell_type":"markdown","source":"Features are the targets we are trying to predict. In combination with the locations of the ","metadata":{}},{"cell_type":"code","source":"features.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.512295Z","iopub.execute_input":"2022-04-28T00:45:34.512614Z","iopub.status.idle":"2022-04-28T00:45:34.52071Z","shell.execute_reply.started":"2022-04-28T00:45:34.512576Z","shell.execute_reply":"2022-04-28T00:45:34.520053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *feature_text* are our targets: the symptoms that we will try to predict using the students notes,\n* The *feature_num* ids each of these *feature_text*.","metadata":{}},{"cell_type":"code","source":"features.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.522157Z","iopub.execute_input":"2022-04-28T00:45:34.522634Z","iopub.status.idle":"2022-04-28T00:45:34.544131Z","shell.execute_reply.started":"2022-04-28T00:45:34.522598Z","shell.execute_reply":"2022-04-28T00:45:34.543317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test & Sample Submission","metadata":{}},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.545869Z","iopub.execute_input":"2022-04-28T00:45:34.546179Z","iopub.status.idle":"2022-04-28T00:45:34.559629Z","shell.execute_reply.started":"2022-04-28T00:45:34.546141Z","shell.execute_reply":"2022-04-28T00:45:34.558748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.560967Z","iopub.execute_input":"2022-04-28T00:45:34.561778Z","iopub.status.idle":"2022-04-28T00:45:34.574478Z","shell.execute_reply.started":"2022-04-28T00:45:34.561733Z","shell.execute_reply":"2022-04-28T00:45:34.573258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* For each patient note, the objective is to predict the span (portion) of the note that correspond to each feature.\n* For example, for the first sample *(00016_000)*, the goal is to find the span of the feature *n°0* for the case *n°0*, in the note *n°16.*","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Merge","metadata":{}},{"cell_type":"markdown","source":"As you've understood, we have 3 tables of relational data. We will now merge the tables to create a flat dataset in order to train a machine learning algorithm.\n\n<img src= \"https://i.ibb.co/Cbrvsx8/flat.png\" alt =\"Embeddings\" style='width: 300px;'>\n\n* *Generates a flat dataset by merging the various tables:*","metadata":{}},{"cell_type":"code","source":"# Merges the patient_notes & features onto the train & test data\ntrain = train.merge(patient_notes,on=['case_num', 'pn_num']).merge(features,on=['case_num', 'feature_num'])\ntest = test.merge(patient_notes,on=['case_num', 'pn_num']).merge(features,on=['case_num', 'feature_num'])","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.576114Z","iopub.execute_input":"2022-04-28T00:45:34.576424Z","iopub.status.idle":"2022-04-28T00:45:34.616268Z","shell.execute_reply.started":"2022-04-28T00:45:34.576384Z","shell.execute_reply":"2022-04-28T00:45:34.615508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Prints the results head out:*","metadata":{}},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.617412Z","iopub.execute_input":"2022-04-28T00:45:34.61778Z","iopub.status.idle":"2022-04-28T00:45:34.630834Z","shell.execute_reply.started":"2022-04-28T00:45:34.61772Z","shell.execute_reply":"2022-04-28T00:45:34.629877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.632427Z","iopub.execute_input":"2022-04-28T00:45:34.633292Z","iopub.status.idle":"2022-04-28T00:45:34.658134Z","shell.execute_reply.started":"2022-04-28T00:45:34.633246Z","shell.execute_reply":"2022-04-28T00:45:34.65726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Targets LabelEncoder","metadata":{}},{"cell_type":"markdown","source":"In order to pass the human readable target data to the machine learning model, we must convert it to numerical data. We use a *LabelEncoder* to transform the data.\n* *Loads or generates the LabelEncoder and transforms the target data:*","metadata":{}},{"cell_type":"code","source":"EMPTY =  'EMPTY'\nCLASSES = [EMPTY,]+features.feature_num.unique().tolist()\n\nif data_exists:\n    # If data exsists, loads the LabelEncoder from disk\n    label_encoder = dill.load(open(f'{input_path}/label_encoder.dill','rb'))\nelse:\n    # Else, generates & fits a new LabelEncoder\n    label_encoder = LabelEncoder()\n    label_encoder.fit(CLASSES)\n    dill.dump(label_encoder,open(f'{output_path}/label_encoder.dill','wb'))\n    \n# Transforms the train & test target data\ntrain['TARGET']= label_encoder.transform(train['feature_num'])\ntest['TARGET']= label_encoder.transform(test['feature_num'])\nN_CLASSES = len(label_encoder.classes_)\nEMPTY_IDX = label_encoder.transform([EMPTY,]) [0]","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.659697Z","iopub.execute_input":"2022-04-28T00:45:34.660049Z","iopub.status.idle":"2022-04-28T00:45:34.686895Z","shell.execute_reply.started":"2022-04-28T00:45:34.660008Z","shell.execute_reply":"2022-04-28T00:45:34.686221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.688316Z","iopub.execute_input":"2022-04-28T00:45:34.688779Z","iopub.status.idle":"2022-04-28T00:45:34.704916Z","shell.execute_reply.started":"2022-04-28T00:45:34.68874Z","shell.execute_reply":"2022-04-28T00:45:34.704125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features Tokenizer","metadata":{}},{"cell_type":"markdown","source":"A *Tokenizer* preprocesses the data so that the model can ingest it.\n* Loads the *Tokenizer* from *HuggingFace*:","metadata":{}},{"cell_type":"code","source":"if data_exists:\n    # If data exsists, loads the Tokenizer from disk\n    tokenizer = AutoTokenizer.from_pretrained(f'{input_path}/my_tokenizer',normalization=True)\nelse:\n    # Else, downloads & initializes the Tokenizer from the cloud\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,normalization=True)\n    tokenizer.save_pretrained(f'{output_path}/my_tokenizer')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:34.706191Z","iopub.execute_input":"2022-04-28T00:45:34.706845Z","iopub.status.idle":"2022-04-28T00:45:43.137145Z","shell.execute_reply.started":"2022-04-28T00:45:34.706799Z","shell.execute_reply":"2022-04-28T00:45:43.136164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is an utility function to decode the locations.\n* *Decodes the locations:* ","metadata":{}},{"cell_type":"code","source":"def decode_location(locations):\n\n    for x in [\"[\", \"]\", \"'\"]:\n        locations = locations.replace(x,'')\n    locations = locations.replace(',', ';')\n    locations = locations.split(\";\")\n    res = []\n    for location in locations:\n        if location:\n            x, y = location.split()\n            res.append((int(x), int(y)))\n    return sorted(res, key=lambda x:x[0])\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-28T00:45:43.138506Z","iopub.execute_input":"2022-04-28T00:45:43.138805Z","iopub.status.idle":"2022-04-28T00:45:43.145111Z","shell.execute_reply.started":"2022-04-28T00:45:43.138769Z","shell.execute_reply":"2022-04-28T00:45:43.144439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if data_exists:\n    # Loads data if it already exists on disk\n    sequences = np.load(open(f'{input_path}/sequences.npy','rb'))\n    masks = np.load(open(f'{input_path}/masks.npy','rb'))\n    labels = np.load(open(f'{input_path}/labels.npy','rb'))\nelse:\n    # Initialize the lists\n    sequences, labels, masks = [], [], []\n    # Groups dataframe by 'pn_num' and iterates over each object\n    for g1 in tqdm(train.groupby('pn_num')):\n        # Get the grouped dataframe\n        gdf = g1[1]\n        # Get whole history note text for each patient\n        pn_history  = gdf.iloc[0].pn_history\n\n        # Apply the tokenizer on the patient history text\n        tokens = tokenizer.encode_plus(\n            pn_history,\n            max_length=SEQUENCE_LENGTH,\n            padding='max_length',\n            truncation=True,\n            return_offsets_mapping=True)\n        # Build the sequence as the tokens input ids according to the sequence lenght\n        sequence = tokens['input_ids']\n        attention_mask = tokens['attention_mask']\n        # Initialize the empty labels\n        label = np.array([EMPTY_IDX for _ in range(SEQUENCE_LENGTH)])\n\n        # BUILDS THE TARGET ARRAY\n        # Getting the tokens\n        offsets = tokens['offset_mapping']\n        label_empty = True\n        for index, row in gdf.iterrows():\n            TARGET = row.TARGET\n            # Setting the targets onto the empty labels\n            for i, (w_start, w_end) in enumerate(offsets):\n                for start,end in decode_location(row.location):\n                    if w_start < w_end and (w_start >= start) and (end >= w_end):\n                        label[i] = TARGET\n                        label_empty = False\n                    if w_start >= w_end:\n                        break\n        # Appending embeddings\n        if not label_empty:\n            sequences.append(sequence)\n            masks.append(attention_mask)\n            labels.append(label)\n        \n    # Formats the data\n    sequences = np.array(sequences).astype(np.int32)\n    masks = np.array(masks).astype(np.uint8)\n    labels = np.array(tf.keras.utils.to_categorical(labels,N_CLASSES)).astype(np.uint8)\n\n    # Saves the data to disk\n    np.save(open(f'{output_path}/sequences.npy','wb'), sequences)\n    np.save(open(f'{output_path}/masks.npy','wb'), masks)\n    np.save(open(f'{output_path}/labels.npy','wb'), labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:45:43.146606Z","iopub.execute_input":"2022-04-28T00:45:43.147055Z","iopub.status.idle":"2022-04-28T00:47:18.903699Z","shell.execute_reply.started":"2022-04-28T00:45:43.147017Z","shell.execute_reply":"2022-04-28T00:47:18.902927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's observe what is actually happening during the *tokenization*.\n* *Prints the last pn_history:*","metadata":{}},{"cell_type":"code","source":"pn_history","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:18.90491Z","iopub.execute_input":"2022-04-28T00:47:18.905257Z","iopub.status.idle":"2022-04-28T00:47:18.910609Z","shell.execute_reply.started":"2022-04-28T00:47:18.905219Z","shell.execute_reply":"2022-04-28T00:47:18.909873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Prints the last sequence:*","metadata":{}},{"cell_type":"code","source":"np.array(sequence)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:18.91182Z","iopub.execute_input":"2022-04-28T00:47:18.912441Z","iopub.status.idle":"2022-04-28T00:47:18.924841Z","shell.execute_reply.started":"2022-04-28T00:47:18.912398Z","shell.execute_reply":"2022-04-28T00:47:18.924092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the *input_ids*, the *SEQUENCE_LENGHT* being 512, we can notice that the terms of the document have been encoded, while the last half of it are encoded with the empty *input_id* (1).\n\n* *Prints the last attention_mask:*","metadata":{}},{"cell_type":"code","source":"np.array(attention_mask)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:18.929758Z","iopub.execute_input":"2022-04-28T00:47:18.929941Z","iopub.status.idle":"2022-04-28T00:47:18.936826Z","shell.execute_reply.started":"2022-04-28T00:47:18.929919Z","shell.execute_reply":"2022-04-28T00:47:18.936069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, kind of the same thing here, except that we only have *1s*, where the model will apply its attention on, and zeroes, where it won't.\n\n* *Prints the last label embeddings:*","metadata":{}},{"cell_type":"code","source":"label","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:18.938277Z","iopub.execute_input":"2022-04-28T00:47:18.939095Z","iopub.status.idle":"2022-04-28T00:47:18.948685Z","shell.execute_reply.started":"2022-04-28T00:47:18.939019Z","shell.execute_reply":"2022-04-28T00:47:18.947775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, in the first half of the embedding, empty labels are encoded with 143, the other ids encode the features of the dataset.","metadata":{}},{"cell_type":"markdown","source":"* [About the *HuggingFace Tokenizer encode plus* use](https://stackoverflow.com/questions/61708486/whats-difference-between-tokenizer-encode-and-tokenizer-encode-plus-in-hugging)\n* [More About the BERT Tokenizers](https://www.analyticsvidhya.com/blog/2021/09/an-explanatory-guide-to-bert-tokenizer/)","metadata":{}},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"* *Converts the embeddings to a TensorFlow dataset:*","metadata":{}},{"cell_type":"code","source":"# Builds the TensorFlow dataset with the embeddings arrays\ntrain_dataset = tf.data.Dataset.from_tensor_slices(\n        ((sequences, masks), labels))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:18.950025Z","iopub.execute_input":"2022-04-28T00:47:18.950403Z","iopub.status.idle":"2022-04-28T00:47:19.090684Z","shell.execute_reply.started":"2022-04-28T00:47:18.950367Z","shell.execute_reply":"2022-04-28T00:47:19.0899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* [About *TensorFlow datasets*](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)","metadata":{}},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"markdown","source":"We are going to generate a validation dataset by applying a split on the *train dataset*. This will enable us to calibrate the model. In order to apply the plit onto the *TensorFlow* dataset, we must use the *TensorFlow* methods *([Source for the function below](https://towardsdatascience.com/how-to-split-a-tensorflow-dataset-into-train-validation-and-test-sets-526c8dd29438))*.\n\n* *Splits the TensorFlow dataset:*","metadata":{}},{"cell_type":"code","source":"def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n    assert (train_split + test_split + val_split) == 1\n    \n    if shuffle:\n        # Specify seed to always have the same split distribution between runs\n        ds = ds.shuffle(shuffle_size, seed=12)\n    \n    train_size = int(train_split * ds_size)\n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)    \n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n    \n    return train_ds, val_ds, test_ds","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.09377Z","iopub.execute_input":"2022-04-28T00:47:19.093979Z","iopub.status.idle":"2022-04-28T00:47:19.099821Z","shell.execute_reply.started":"2022-04-28T00:47:19.093954Z","shell.execute_reply":"2022-04-28T00:47:19.099175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We keep 80% of the data for training and 20% for validation.\n* *Generates training & validation datasets:*","metadata":{}},{"cell_type":"code","source":"samples = sequences.shape[0]\ntrain_dataset, val_dataset, test_df = get_dataset_partitions_tf(\n    train_dataset,\n    train_split=TRAIN_SPLIT,\n    val_split=0.2,\n    test_split=0,\n    ds_size=samples)\n\ntrain_dataset, val_dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.100874Z","iopub.execute_input":"2022-04-28T00:47:19.101737Z","iopub.status.idle":"2022-04-28T00:47:19.127701Z","shell.execute_reply.started":"2022-04-28T00:47:19.101699Z","shell.execute_reply":"2022-04-28T00:47:19.126907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We use the *TensorFlow* datasets to create generators *with options* which will enable for parallel GPUs training.\n\n***Note that as we are implementing generators to pass the data to the model, the batch_size parameter is set during the generators initialization, not during model fit.***\n\n* *Creates TensorFlow generators:*","metadata":{}},{"cell_type":"code","source":"# Creates repeating generators with options and the set batch sizer with the datasets\ntrain_dataset = train_dataset.repeat().batch(BATCH_SIZE).with_options(options)\nval_dataset = val_dataset.repeat().batch(BATCH_SIZE).with_options(options)\n\ntrain_dataset, val_dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.129187Z","iopub.execute_input":"2022-04-28T00:47:19.129471Z","iopub.status.idle":"2022-04-28T00:47:19.142555Z","shell.execute_reply.started":"2022-04-28T00:47:19.129436Z","shell.execute_reply":"2022-04-28T00:47:19.141933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another specificity of using generators: we must calculate the steps per epochs for both datasets (for the validation dataset, they're called \"validation steps\"). These variables will be passed to the fit function.\n* *Computes numbers of steps to pass to the step function:*","metadata":{}},{"cell_type":"code","source":"steps_per_epoch = (samples * TRAIN_SPLIT) // BATCH_SIZE\nvalidation_steps = (samples * (1 - TRAIN_SPLIT)) // BATCH_SIZE\n\nsteps_per_epoch, validation_steps","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.143811Z","iopub.execute_input":"2022-04-28T00:47:19.144064Z","iopub.status.idle":"2022-04-28T00:47:19.15003Z","shell.execute_reply.started":"2022-04-28T00:47:19.144022Z","shell.execute_reply":"2022-04-28T00:47:19.149216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* [About *TensorFlow distributed datasets*](https://www.tensorflow.org/api_docs/python/tf/distribute/DistributedDataset)","metadata":{}},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"markdown","source":"In addition, we implemented callbakcs:\n* *EarlyStopping*: stops the model training if the performance of the model is not improving.\n* *ModelCheckpoint*: saves the weights of the best model on disk (*best epoch*).\n* *LearningRateScheduler*: implements the learning rate decay at each epoch.","metadata":{}},{"cell_type":"markdown","source":"### Early Stopping","metadata":{}},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='loss',\n    mode='min',\n    patience=3)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.151588Z","iopub.execute_input":"2022-04-28T00:47:19.151833Z","iopub.status.idle":"2022-04-28T00:47:19.158341Z","shell.execute_reply.started":"2022-04-28T00:47:19.151798Z","shell.execute_reply":"2022-04-28T00:47:19.157517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Checkpoint","metadata":{}},{"cell_type":"code","source":"model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    f'{output_path}/model.h5',\n    monitor=\"f1_score\",\n    verbose=0,\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"max\",\n    save_freq=\"epoch\",\n    options=None,\n    initial_value_threshold=None)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.159816Z","iopub.execute_input":"2022-04-28T00:47:19.160091Z","iopub.status.idle":"2022-04-28T00:47:19.166237Z","shell.execute_reply.started":"2022-04-28T00:47:19.160039Z","shell.execute_reply":"2022-04-28T00:47:19.16544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Creates the list of callbacks:*","metadata":{}},{"cell_type":"code","source":"callbacks = [early_stopping, model_checkpoint]","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.167659Z","iopub.execute_input":"2022-04-28T00:47:19.167974Z","iopub.status.idle":"2022-04-28T00:47:19.176514Z","shell.execute_reply.started":"2022-04-28T00:47:19.167941Z","shell.execute_reply":"2022-04-28T00:47:19.175725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"## Model Configuration","metadata":{}},{"cell_type":"markdown","source":"* Loads the transfomers configuration:","metadata":{}},{"cell_type":"code","source":"if data_exists:\n    # If data exsists, loads the config from disk\n    config = AutoConfig.from_pretrained(f'{input_path}/my_tokenizer/config.json')\nelse:\n    # Else, downloads & initializes the config from the cloud\n    config = AutoConfig.from_pretrained(MODEL_NAME)\n    config.save_pretrained(f'{output_path}/my_tokenizer')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.177715Z","iopub.execute_input":"2022-04-28T00:47:19.178045Z","iopub.status.idle":"2022-04-28T00:47:19.655436Z","shell.execute_reply.started":"2022-04-28T00:47:19.178009Z","shell.execute_reply":"2022-04-28T00:47:19.654625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Prints the configuration:*","metadata":{}},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.656794Z","iopub.execute_input":"2022-04-28T00:47:19.657106Z","iopub.status.idle":"2022-04-28T00:47:19.665262Z","shell.execute_reply.started":"2022-04-28T00:47:19.657062Z","shell.execute_reply":"2022-04-28T00:47:19.664266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build","metadata":{}},{"cell_type":"markdown","source":"To build the model, we use the *HuggingFace & TensorFlow APIs*: we've already used the *HuggingFace API* to import the *Tokenizer* & preprocess the data. We will now use the API to import the pre-trained model as a *TensorFlow* model.\n\nWe use the *functional TensorFlow API* to integrate the *pre-trained BERT model* &:\n* build the input layer of the network,\n* build the output layer of the network,\n* compile the model.","metadata":{}},{"cell_type":"markdown","source":"* *Builds the ready for training model:*","metadata":{}},{"cell_type":"code","source":"def build_model(data_exists, config):\n    \n    # Creates input layers\n    tokens = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), name = 'tokens', dtype=tf.int32)\n    attention = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), name = 'attention', dtype=tf.int32)\n    \n    if data_exists:\n        # Initializes the AutoConfig Model from disk\n        backbone = TFAutoModel.from_config(config)\n    else:\n        # Initializes the AutoConfig Model from the cloud\n        backbone = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n    \n    # Output layers\n    out = backbone(tokens, attention_mask=attention)[0]\n    out = tf.keras.layers.Dropout(0.2)(out)\n    # Sets the output activation to softmax\n    out = tf.keras.layers.Dense(N_CLASSES, activation='softmax')(out)\n    \n    # Generates the model structure\n    model = tf.keras.Model([tokens, attention], out)\n    \n    # Compiles the model\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(5e-5),\n        loss=tf.keras.losses.categorical_crossentropy,\n        metrics=[tfa.metrics.F1Score(num_classes=N_CLASSES, average='micro')])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.666892Z","iopub.execute_input":"2022-04-28T00:47:19.667856Z","iopub.status.idle":"2022-04-28T00:47:19.678398Z","shell.execute_reply.started":"2022-04-28T00:47:19.667813Z","shell.execute_reply":"2022-04-28T00:47:19.677499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fit","metadata":{}},{"cell_type":"markdown","source":"We fit the model using the:\n* model build,\n* training & validation generators,\n* generators *steps per epoch & validation steps*,\n* and choosen number of *epochs*,\n* *list* of *callbacks*.","metadata":{}},{"cell_type":"markdown","source":"* *Fits the model build:*","metadata":{}},{"cell_type":"code","source":"def fit_model(model, train_ds, val_ds, steps_per_epoch, validation_steps, callbacks, epochs=10):\n    \n    # Fits the model\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        callbacks=callbacks,\n        epochs=epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_steps=validation_steps)\n\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.681688Z","iopub.execute_input":"2022-04-28T00:47:19.681944Z","iopub.status.idle":"2022-04-28T00:47:19.687275Z","shell.execute_reply.started":"2022-04-28T00:47:19.681882Z","shell.execute_reply":"2022-04-28T00:47:19.686505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"* *Builds & fits the model if TRAIN is set to True:*","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    with strategy.scope():\n        \n        # Builds the model\n        model = build_model(data_exists, config)\n        # Fits the model\n        model, history = fit_model(\n            model,\n            train_dataset,\n            val_dataset,\n            steps_per_epoch,\n            validation_steps,\n            callbacks,\n            epochs=EPOCHS)\n\n    # The model weights are saved thanks to the checkpoint callback","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:47:19.688934Z","iopub.execute_input":"2022-04-28T00:47:19.689447Z","iopub.status.idle":"2022-04-28T00:49:14.351587Z","shell.execute_reply.started":"2022-04-28T00:47:19.689407Z","shell.execute_reply":"2022-04-28T00:49:14.350741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"markdown","source":"* *Plots the model accuracy history:*","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    # Summarizes history for accuracy\n    plt.plot(history.history['f1_score'])\n    plt.plot(history.history['val_f1_score'])\n    plt.title('model f1_score')\n    plt.ylabel('f1_score')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:14.352996Z","iopub.execute_input":"2022-04-28T00:49:14.353291Z","iopub.status.idle":"2022-04-28T00:49:14.592729Z","shell.execute_reply.started":"2022-04-28T00:49:14.353249Z","shell.execute_reply":"2022-04-28T00:49:14.592032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Plots the model loss history:*","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    # SUmmarizes history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:14.593874Z","iopub.execute_input":"2022-04-28T00:49:14.594116Z","iopub.status.idle":"2022-04-28T00:49:14.790141Z","shell.execute_reply.started":"2022-04-28T00:49:14.594083Z","shell.execute_reply":"2022-04-28T00:49:14.789426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The model merges perfectly.*\n\n* [About *Transformers Fine Tuning*](https://huggingface.co/docs/transformers/training#finetune-with-keras)","metadata":{}},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"markdown","source":"## Load model","metadata":{}},{"cell_type":"markdown","source":"* *If the data exists, loads the model from disk:*","metadata":{}},{"cell_type":"code","source":"if data_exists:\n    config = AutoConfig.from_pretrained(f'{input_path}/my_tokenizer/config.json')\n    backbone = TFAutoModel.from_config(config)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:14.791468Z","iopub.execute_input":"2022-04-28T00:49:14.791888Z","iopub.status.idle":"2022-04-28T00:49:14.796385Z","shell.execute_reply.started":"2022-04-28T00:49:14.791848Z","shell.execute_reply":"2022-04-28T00:49:14.795616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Model","metadata":{}},{"cell_type":"markdown","source":"* *If no model has been trained, builds the model:*","metadata":{}},{"cell_type":"code","source":"if not TRAIN:\n    model = build_model(data_exists, config)\n    model.load_weights(f'{input_path}/model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:14.797889Z","iopub.execute_input":"2022-04-28T00:49:14.79815Z","iopub.status.idle":"2022-04-28T00:49:14.804601Z","shell.execute_reply.started":"2022-04-28T00:49:14.798116Z","shell.execute_reply":"2022-04-28T00:49:14.803894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Plots the model structure:*","metadata":{}},{"cell_type":"code","source":"tf.keras.utils.plot_model(\n            model=model,\n            show_shapes=True,\n            show_dtype=False,\n            show_layer_names=True,\n            rankdir='TB',\n            expand_nested=True,\n            dpi=96,\n            layer_range=None)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:14.80594Z","iopub.execute_input":"2022-04-28T00:49:14.806192Z","iopub.status.idle":"2022-04-28T00:49:15.683167Z","shell.execute_reply.started":"2022-04-28T00:49:14.806159Z","shell.execute_reply":"2022-04-28T00:49:15.682369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"markdown","source":"* *Prepares the test data for prediction:*","metadata":{}},{"cell_type":"code","source":"test_sequences, test_masks, test_offsets = [], [],[]\nrow_ids = []\ntargets = []\n\nfor g1 in tqdm(test.groupby('pn_num')):\n\n    gdf = g1[1]\n    pn_history  = gdf.iloc[0].pn_history\n    targets.append([])\n    row_ids.append([])\n    \n    test_tokens = tokenizer.encode_plus(pn_history, max_length=SEQUENCE_LENGTH, padding='max_length',truncation=True, return_offsets_mapping=True)\n    test_sequence = test_tokens['input_ids']\n    test_attention_mask = test_tokens['attention_mask'] \n\n    # BUILD THE TARGET ARRAY\n    offset = test_tokens['offset_mapping']\n\n    for index, row in gdf.iterrows():\n\n        targets[-1].append(row.TARGET)\n        row_ids[-1].append(row.id)\n         \n    test_sequences.append(test_sequence)\n    test_masks.append(test_attention_mask)\n    test_offsets.append(offset)\n\ntest_sequences = np.array(test_sequences).astype(np.int32)\ntest_masks = np.array(test_masks).astype(np.uint8)\ntargets_to_row_ids = [dict(zip(a,b)) for a,b in zip(targets,row_ids)]","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:15.685095Z","iopub.execute_input":"2022-04-28T00:49:15.685411Z","iopub.status.idle":"2022-04-28T00:49:15.73895Z","shell.execute_reply.started":"2022-04-28T00:49:15.685368Z","shell.execute_reply":"2022-04-28T00:49:15.738243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Generates the TensorFlow test dataset:*","metadata":{}},{"cell_type":"code","source":"# Builds the TensorFlow dataset with the embeddings arrays\ntest_dataset = tf.data.Dataset.from_tensor_slices(\n        ((test_sequences, test_masks),)).batch(BATCH_SIZE).with_options(options)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:15.740426Z","iopub.execute_input":"2022-04-28T00:49:15.740899Z","iopub.status.idle":"2022-04-28T00:49:15.75101Z","shell.execute_reply.started":"2022-04-28T00:49:15.74086Z","shell.execute_reply":"2022-04-28T00:49:15.750161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Generates the predictions:*","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n\n    preds = model.predict(test_dataset,batch_size=BATCH_SIZE)\n\npreds = np.argmax(preds, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:15.753065Z","iopub.execute_input":"2022-04-28T00:49:15.753775Z","iopub.status.idle":"2022-04-28T00:49:19.900796Z","shell.execute_reply.started":"2022-04-28T00:49:15.753612Z","shell.execute_reply":"2022-04-28T00:49:19.900033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit predictions","metadata":{}},{"cell_type":"markdown","source":"* *Functions to inverse transform predictions:*","metadata":{}},{"cell_type":"code","source":"def decode_position(pos):\n\n    return \";\".join([\" \".join(np.array(p).astype(str)) for p in pos])\n\n\ndef translate(preds,targets_to_row_ids,offsets):\n\n    all_ids = []\n    all_pos = []\n\n    for k in range(len(preds)):\n\n        offset = offsets[k]\n        pred = preds[k]\n        targets_to_ids = targets_to_row_ids[k]\n\n        prediction = {targets_to_ids[t]:[] for t in targets_to_ids}\n        i = 0\n\n        while i<SEQUENCE_LENGTH:\n            label = pred[i]\n            \n            if label == EMPTY_IDX:\n                i += 1\n                continue\n            if label in targets_to_ids:\n                key = targets_to_ids[label]\n                start = offset[i][0]\n                while i<SEQUENCE_LENGTH:\n                    if pred[i] != label:\n                        break\n                    else:\n                        end = max(offset[i])\n                    i += 1\n                if  end == 0:\n                    break\n                prediction[key].append((start, end))\n            else:\n                i+=1\n\n        for key in prediction:\n        \n            all_ids.append(key)\n            all_pos.append(decode_position(prediction[key]))\n\n    df = pd.DataFrame({\n        \"id\": all_ids,\n        \"location\": all_pos\n    })\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-28T00:49:19.902141Z","iopub.execute_input":"2022-04-28T00:49:19.902432Z","iopub.status.idle":"2022-04-28T00:49:19.914493Z","shell.execute_reply.started":"2022-04-28T00:49:19.902398Z","shell.execute_reply":"2022-04-28T00:49:19.913693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Translates predictions and save as .csv file:*","metadata":{}},{"cell_type":"code","source":"sub = translate(preds, targets_to_row_ids, test_offsets)\nsub.to_csv('submission.csv',index=False)\nsub.head(50)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T00:49:19.915939Z","iopub.execute_input":"2022-04-28T00:49:19.916231Z","iopub.status.idle":"2022-04-28T00:49:19.935891Z","shell.execute_reply.started":"2022-04-28T00:49:19.916181Z","shell.execute_reply":"2022-04-28T00:49:19.935254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"We have successfully implemented a *transformer* to solve a *Named Entity Recognition* task and participate in this competition !\n\nI hope you've learned a few things.\n\n*Thibaud*","metadata":{}}]}